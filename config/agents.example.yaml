# Multi-Agent System Configuration Example
# 多智能体系统配置文件示例
#
# 使用方法：
# 1. 复制此文件为 agents.yaml
# 2. 配置环境变量（如 OPENAI_API_KEY）
# 3. 根据需要启用/禁用或修改Agent配置

# 系统配置
system:
  log_level: INFO  # 日志级别: DEBUG, INFO, WARNING, ERROR
  log_format: "%(asctime)s - %(name)s - %(levelname)s - %(message)s"

# ===================================
# 全局LLM Providers配置
# ===================================
# 在此处统一配置API密钥和模型参数
# 所有Agent通过引用provider名称来使用LLM
llm_providers:
  # OpenAI GPT-4 通用配置
  openai-gpt4:
    provider: openai
    model: "gpt-4"
    api_key: "${OPENAI_API_KEY}"  # 环境变量，执行前需设置
    base_url: null                # 可选，OpenAI兼容API的base URL
                                  # 例如: "https://api.openai.com/v1" (默认)
                                  #      "https://your-azure-endpoint.openai.azure.com"
                                  #      "http://localhost:11434/v1" (本地Ollama)
    temperature: 0.7              # 0.0-2.0，值越高越有创造性
    max_tokens: 2000              # 最大生成token数
    timeout: 60.0                 # 请求超时（秒）
    max_retries: 3                # 最大重试次数

  # OpenAI GPT-4 代码专用配置
  openai-gpt4-coder:
    provider: openai
    model: "gpt-4"
    api_key: "${OPENAI_API_KEY}"
    base_url: null
    temperature: 0.3  # 更低温度获得更确定性的代码
    max_tokens: 4000  # 更多token用于长代码
    timeout: 90.0
    max_retries: 3

  # OpenAI GPT-3.5 Turbo（更快更便宜）
  openai-gpt35:
    provider: openai
    model: "gpt-3.5-turbo"
    api_key: "${OPENAI_API_KEY}"
    base_url: null
    temperature: 0.7
    max_tokens: 2000
    timeout: 30.0
    max_retries: 3

  # Azure OpenAI 配置示例
  # azure-gpt4:
  #   provider: azure_openai
  #   model: "your-deployment-name"          # Azure部署名称（不是模型名称）
  #   api_key: "${AZURE_OPENAI_KEY}"         # Azure OpenAI API密钥
  #   base_url: "https://your-resource.openai.azure.com"  # Azure资源端点
  #   api_version: "2025-04-01-preview"      # API版本（必需）
  #   temperature: 0.7
  #   max_tokens: 2000
  #   timeout: 60.0
  #   max_retries: 3

  # Anthropic Claude配置示例（需要实现Anthropic provider）
  # anthropic-claude:
  #   provider: anthropic
  #   model: "claude-3-opus-20240229"
  #   api_key: "${ANTHROPIC_API_KEY}"
  #   temperature: 1.0
  #   max_tokens: 4096
  #   timeout: 60.0

  # 本地模型配置示例（需要实现local provider）
  # local-llama:
  #   provider: local
  #   model: "llama2"
  #   base_url: "http://localhost:11434"  # Ollama API地址
  #   temperature: 0.8
  #   max_tokens: 2048

# ===================================
# 全局MCP服务器配置
# ===================================
# MCP (Model Context Protocol) 服务器提供外部工具能力
# MCP Agent 可以引用这些服务器来访问各种工具
#
# 支持三种传输协议：
# 1. stdio - 本地进程通信（适用于npm包）
# 2. sse - 服务器发送事件（适用于远程HTTP服务）
# 3. streamable_http - 流式HTTP（适用于远程HTTP服务）

mcp_servers:
  # 远程 DeepWiki SSE 服务器 - 推荐！
  # 无需安装，直接连接远程服务
  deepwiki-remote:
    transport: sse  # 或 streamable_http
    url: "https://mcp.deepwiki.com/sse"
    description: "GitHub repository exploration (remote)"
    # 注意：远程服务器不需要 command 和 args 字段

  # 本地 DeepWiki - 需要安装 npm 包
  # 需要安装: npm install -g @deepwiki/mcp
  # deepwiki-local:
  #   transport: stdio  # 传输方式: stdio, sse, streamable_http
  #   command: npx      # 启动命令
  #   args:
  #     - "-y"
  #     - "@deepwiki/mcp"
  #   env:
  #     DEEPWIKI_API_KEY: "${DEEPWIKI_API_KEY}"  # 环境变量
  #   description: "GitHub repository exploration (local)"

  # Brave Search - Web搜索工具
  # 需要安装: npm install -g @modelcontextprotocol/server-brave-search
  # brave-search:
  #   transport: stdio
  #   command: npx
  #   args:
  #     - "-y"
  #     - "@modelcontextprotocol/server-brave-search"
  #   env:
  #     BRAVE_API_KEY: "${BRAVE_API_KEY}"
  #   description: "Web search using Brave Search API"

  # SQLite Database - 数据库访问工具
  # sqlite-db:
  #   transport: stdio
  #   command: npx
  #   args:
  #     - "-y"
  #     - "@modelcontextprotocol/server-sqlite"
  #     - "/path/to/database.db"  # 数据库路径
  #   description: "SQLite database access and querying"

  # Filesystem - 文件系统访问（只读）
  # filesystem:
  #   transport: stdio
  #   command: npx
  #   args:
  #     - "-y"
  #     - "@modelcontextprotocol/server-filesystem"
  #     - "/path/to/allowed/directory"  # 允许访问的目录
  #   description: "Read-only filesystem access"

# ===================================
# Agent配置列表
# ===================================
agents:
  # Echo Agent - 简单回声Agent（无需LLM）
  - name: echo
    description: "A simple echo agent that demonstrates A2A protocol capabilities"
    type: echo           # Agent类型
    host: 0.0.0.0        # 监听地址
    port: 9001           # 端口（必须唯一）

    # 自定义URL（可选）
    # 如果不设置，将自动生成为 http://localhost:{port}
    # 在使用端口转发、反向代理或云端notebook时很有用
    # 例如端口转发: url: "https://example.com/proxy/9001/"
    # 例如ngrok: url: "https://abc123.ngrok.io"
    # 例如云端notebook: url: "https://nat-notebook.example.com/ws-xxx/proxy/9001/"
    # url: "https://your-custom-url.com"

    # Provider信息（可选）
    provider:
      organization: "Demo Organization"
      url: "https://example.com"      # 可选
      email: "support@example.com"    # 可选

  # GPT Assistant - GPT-4驱动的通用助手
  - name: gpt-assistant
    description: "An AI assistant powered by GPT-4 for general conversations"
    type: llm
    host: 0.0.0.0
    port: 9002
    llm_provider: openai-gpt4  # 引用上面定义的provider
    provider:
      organization: "AI Research Lab"
      url: "https://ai-lab.example.com"
    # 额外配置
    extra:
      system_prompt: "You are a helpful AI assistant. Be concise and friendly."

  # GPT Coder - GPT-4专门用于代码的Agent
  - name: gpt-coder
    description: "An AI coding assistant powered by GPT-4, specialized in programming"
    type: llm
    host: 0.0.0.0
    port: 9003
    llm_provider: openai-gpt4-coder  # 引用代码专用配置
    provider:
      organization: "Code Helper Inc"
    extra:
      system_prompt: |
        You are an expert programming assistant.
        Provide clear, well-commented code with explanations.
        Follow best practices and prioritize code quality.

  # Translator - 专业翻译助手
  - name: translator
    description: "A professional translation agent that supports multiple languages and translation styles"
    type: llm
    host: 0.0.0.0
    port: 9004
    llm_provider: openai-gpt4  # 使用 GPT-4 进行翻译
    provider:
      organization: "Translation Services"
      url: "https://translate.example.com"
    extra:
      system_prompt: |
        You are a professional translator with expertise in multiple languages and translation styles.

        CAPABILITIES:
        - Translate text between any language pairs
        - Adapt translation style based on context and user requirements
        - Preserve meaning, tone, and nuances of the original text
        - Handle technical, literary, formal, and casual content

        INTERACTION FORMAT:
        Users may specify their translation requirements in various ways:
        1. "Translate to [language]: [text]"
        2. "Translate to [language] in [style] style: [text]"
        3. Or simply provide text with language/style context in their message

        SUPPORTED STYLES:
        - formal: Professional, business communication
        - casual: Everyday conversation, informal tone
        - technical: Specialized terminology, precise and accurate
        - literary: Creative, expressive, preserving artistic elements
        - academic: Scholarly, research-oriented

        GUIDELINES:
        1. If target language is not specified, ask the user to clarify
        2. If style is not specified, use a neutral, natural style
        3. For ambiguous terms, provide the most contextually appropriate translation
        4. Preserve formatting, punctuation, and structure when appropriate
        5. For idioms or culturally-specific expressions, provide equivalent expressions in the target language
        6. If a term has no direct translation, provide an explanation

        RESPONSE FORMAT:
        Provide the translation directly without unnecessary preamble. If clarification is needed, ask concisely.

        Examples:
        User: "Translate to French: Hello, how are you?"
        Assistant: "Bonjour, comment allez-vous ?"

        User: "Translate to Japanese in formal style: I would like to request a meeting"
        Assistant: "会議をお願いしたく存じます。"

        User: "Translate this to Spanish in casual style: What's up?"
        Assistant: "¿Qué tal?"

  # GPT-3.5 Quick Assistant - 使用GPT-3.5的快速助手（已注释）
  # 取消注释以启用此Agent
  # - name: quick-assistant
  #   description: "A faster AI assistant powered by GPT-3.5 Turbo"
  #   type: llm
  #   host: 0.0.0.0
  #   port: 9005
  #   llm_provider: openai-gpt35
  #   extra:
  #     system_prompt: "You are a helpful assistant. Provide quick and concise answers."

  # ===================================
  # MCP Agent 示例
  # ===================================
  # Research Assistant - 具有GitHub探索和Web搜索能力的研究助手（已注释）
  # 需要：
  # 1. 配置 OPENAI_API_KEY 环境变量（用于LLM推理）
  # 2. 如使用远程服务，无需额外配置；如使用本地服务，需安装相应MCP服务器
  # - name: research-assistant
  #   description: "AI research assistant with GitHub exploration capabilities"
  #   type: mcp                      # Agent类型：mcp
  #   host: 0.0.0.0
  #   port: 9010
  #   llm_provider: openai-gpt4      # 用于工具调用决策的LLM
  #   provider:
  #     organization: "Research Tools"
  #     url: "https://research.example.com"
  #   extra:
  #     mcp_config:
  #       servers:                   # 引用的MCP服务器列表
  #         - deepwiki-remote        # 使用远程DeepWiki服务（推荐）
  #         # - deepwiki-local       # 或使用本地服务（需要npm安装）
  #         # - brave-search         # Web搜索（需要取消注释brave-search配置）
  #       system_prompt: |           # 自定义系统提示词（可选）
  #         You are a research assistant with access to powerful tools:
  #         - GitHub repository exploration (deepwiki)
  #
  #         When users ask questions:
  #         1. Determine if you need to use tools to answer
  #         2. Use the appropriate tools to gather information
  #         3. Synthesize the information into a clear, helpful answer
  #
  #         Always cite your sources when using tool results.
  #       max_tool_calls: 5          # 单次对话最大工具调用次数
  #       tool_choice: auto          # auto, required, none

# ===================================
# 添加新Agent的步骤
# ===================================
# 1. 如果需要新的LLM配置，先在 llm_providers 中添加
# 2. 如果是MCP Agent，先在 mcp_servers 中添加需要的MCP服务器
# 3. 在 agents 列表中添加新的Agent配置
# 4. 确保端口号唯一
# 5. 如果是LLM或MCP类型，指定 llm_provider
# 6. 在 extra.system_prompt 中定义Agent的行为
# 7. 对于MCP Agent，在 extra.mcp_config 中配置工具服务器

# ===================================
# MCP Agent 配置说明
# ===================================
# MCP (Model Context Protocol) Agent 可以调用外部工具服务器
#
# 必需字段：
# - type: mcp
# - llm_provider: 引用LLM provider（用于工具调用决策）
# - extra.mcp_config.servers: 引用的MCP服务器列表
#
# 可选字段：
# - extra.mcp_config.system_prompt: 自定义系统提示词
# - extra.mcp_config.max_tool_calls: 最大工具调用次数（默认5）
# - extra.mcp_config.tool_choice: 工具调用策略（auto/required/none，默认auto）
#
# 示例MCP服务器：
# - @deepwiki/mcp: GitHub仓库探索
# - @modelcontextprotocol/server-brave-search: Web搜索
# - @modelcontextprotocol/server-sqlite: SQLite数据库
# - @modelcontextprotocol/server-filesystem: 文件系统访问
#
# 更多MCP服务器: https://github.com/modelcontextprotocol/servers
